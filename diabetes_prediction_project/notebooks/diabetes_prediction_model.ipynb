{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Model\n",
    "\n",
    "This notebook contains a comprehensive analysis and prediction model for diabetes using a large dataset with 100,000 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Diabetes is a chronic disease that affects how your body turns food into energy. It occurs when your blood glucose (blood sugar) is too high. Blood glucose is your main source of energy and comes from the food you eat. Insulin, a hormone made by the pancreas, helps glucose from food get into your cells to be used for energy.\n",
    "\n",
    "Early detection of diabetes is crucial for effective management and prevention of complications. In this project, we will build a machine learning model to predict whether a person has diabetes based on various health metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries for data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Import libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Dataset\n",
    "\n",
    "Let's load the dataset and take a look at its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the dataset\n",
    "print(\"Dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of the dataset\n",
    "print(\"Statistical summary of numerical features:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable\n",
    "print(\"Distribution of diabetes (target variable):\")\n",
    "print(df['diabetes'].value_counts())\n",
    "print(f\"Percentage of diabetic patients: {df['diabetes'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='diabetes', data=df)\n",
    "plt.title('Distribution of Diabetes')\n",
    "plt.xlabel('Diabetes (0: No, 1: Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/diabetes_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing\n",
    "\n",
    "Let's clean the data and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "print(\"Unique values in 'gender':\")\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"\\nUnique values in 'smoking_history':\")\n",
    "print(df['smoking_history'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle any missing values if they exist\n",
    "# For numerical columns, fill with median\n",
    "numerical_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "categorical_cols = ['gender', 'smoking_history']\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "print(\"First 5 rows of the encoded dataset:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the relationships between different features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='age', hue='diabetes', kde=True, bins=30)\n",
    "plt.title('Age Distribution by Diabetes Status')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/age_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of BMI\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='bmi', hue='diabetes', kde=True, bins=30)\n",
    "plt.title('BMI Distribution by Diabetes Status')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/bmi_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of HbA1c level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='HbA1c_level', hue='diabetes', kde=True, bins=30)\n",
    "plt.title('HbA1c Level Distribution by Diabetes Status')\n",
    "plt.xlabel('HbA1c Level')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/hba1c_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of blood glucose level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='blood_glucose_level', hue='diabetes', kde=True, bins=30)\n",
    "plt.title('Blood Glucose Level Distribution by Diabetes Status')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/glucose_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "# Select only numerical columns for correlation\n",
    "numerical_df = df[['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = numerical_df.corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.savefig('../images/correlation_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes prevalence by gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='gender', hue='diabetes', data=df)\n",
    "plt.title('Diabetes Prevalence by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/diabetes_by_gender.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes prevalence by smoking history\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='smoking_history', hue='diabetes', data=df)\n",
    "plt.title('Diabetes Prevalence by Smoking History')\n",
    "plt.xlabel('Smoking History')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('../images/diabetes_by_smoking.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes prevalence by hypertension\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='hypertension', hue='diabetes', data=df)\n",
    "plt.title('Diabetes Prevalence by Hypertension')\n",
    "plt.xlabel('Hypertension (0: No, 1: Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/diabetes_by_hypertension.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes prevalence by heart disease\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='heart_disease', hue='diabetes', data=df)\n",
    "plt.title('Diabetes Prevalence by Heart Disease')\n",
    "plt.xlabel('Heart Disease (0: No, 1: Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('../images/diabetes_by_heart_disease.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for numerical features\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.pairplot(data=df, vars=['age', 'bmi', 'HbA1c_level', 'blood_glucose_level'], hue='diabetes')\n",
    "plt.savefig('../images/pairplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection and Data Preparation\n",
    "\n",
    "Let's prepare our data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_encoded.drop('diabetes', axis=1)\n",
    "y = df_encoded['diabetes']\n",
    "\n",
    "# Display the features\n",
    "print(\"Features used for modeling:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Building and Evaluation\n",
    "\n",
    "Let's build and evaluate different machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression model\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('../images/lr_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for logistic regression\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../images/lr_roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_dt):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_dt):.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Decision Tree')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('../images/dt_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for decision tree\n",
    "y_pred_proba_dt = dt_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_proba_dt)\n",
    "auc_dt = roc_auc_score(y_test, y_pred_proba_dt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Decision Tree')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../images/dt_roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a random forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('../images/rf_confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for random forest\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../images/rf_roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ROC curves of all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.4f})')\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.4f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Model Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../images/model_comparison_roc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance metrics\n",
    "models = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "accuracy = [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_rf)]\n",
    "precision = [precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_dt), precision_score(y_test, y_pred_rf)]\n",
    "recall = [recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_dt), recall_score(y_test, y_pred_rf)]\n",
    "f1 = [f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_dt), f1_score(y_test, y_pred_rf)]\n",
    "auc = [auc_lr, auc_dt, auc_rf]\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'AUC': auc\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "comparison_data = comparison_df[metrics].values\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "x = np.arange(len(models))\n",
    "width = 0.15\n",
    "multiplier = 0\n",
    "\n",
    "for attribute, measurement in zip(metrics, comparison_data.T):\n",
    "    offset = width * multiplier\n",
    "    rects = plt.bar(x + offset, measurement, width, label=attribute)\n",
    "    plt.bar_label(rects, fmt='%.2f', padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x + width * 2, models)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5)\n",
    "plt.ylim(0, 1.2)\n",
    "plt.savefig('../images/model_comparison_metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "plt.title('Top 10 Feature Importance from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Interpretation and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis, we can draw the following insights:\n",
    "\n",
    "1. **Model Performance**: The Random Forest model performed the best among the three models we built, with the highest accuracy, precision, recall, F1 score, and AUC.\n",
    "\n",
    "2. **Key Predictors**: The most important features for predicting diabetes are:\n",
    "   - Blood glucose level\n",
    "   - HbA1c level\n",
    "   - Age\n",
    "   - BMI\n",
    "\n",
    "3. **Medical Relevance**: This aligns with medical knowledge, as high blood glucose levels and HbA1c levels are directly related to diabetes diagnosis.\n",
    "\n",
    "4. **Risk Factors**: Age and BMI are significant risk factors for diabetes, which is also consistent with medical literature.\n",
    "\n",
    "5. **Gender and Lifestyle Factors**: Gender and smoking history have some influence on diabetes risk, but they are less important than the physiological measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, we built and compared three machine learning models to predict diabetes based on various health metrics. The Random Forest model performed the best, achieving high accuracy and AUC scores. The most important predictors were blood glucose level, HbA1c level, age, and BMI.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Regular Monitoring**: Individuals should regularly monitor their blood glucose and HbA1c levels, especially if they are in high-risk categories (older age, high BMI).\n",
    "\n",
    "2. **Lifestyle Changes**: Maintaining a healthy BMI through diet and exercise can significantly reduce the risk of developing diabetes.\n",
    "\n",
    "3. **Early Intervention**: Early detection and intervention can help manage diabetes effectively and prevent complications.\n",
    "\n",
    "4. **Model Deployment**: This model could be integrated into healthcare systems to help identify high-risk individuals who may benefit from preventive interventions.\n",
    "\n",
    "5. **Further Research**: Future work could explore more complex models or incorporate additional features such as dietary habits, physical activity levels, and family history for even more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import joblib for saving the model\n",
    "import joblib\n",
    "\n",
    "# Save the Random Forest model (best performing model)\n",
    "joblib.dump(rf_model, '../src/diabetes_prediction_model.pkl')\n",
    "\n",
    "# Save the scaler for preprocessing new data\n",
    "joblib.dump(scaler, '../src/scaler.pkl')\n",
    "\n",
    "print(\"Model and scaler saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
